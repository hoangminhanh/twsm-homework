{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_TextRepresentation(2).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDxVgBH5VuTwMqGwDFLXaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangminhanh/twsm-homework/blob/main/HW5_TextRepresentation(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovoHQk2YqdpW",
        "outputId": "e35405f1-e8a5-4214-e3dc-2cf03920ba1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 7.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ffb2380a9542c795d20524c27a8610079a375c70900225f2c53d8140ab9e1163\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the important packages\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "SLIxR40IqqRA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the GG Drive\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Importing the Lemmatized data from Google Drive\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/TWSM\"\n",
        "infile = open(data_path+'/Lemma.pkl','rb')\n",
        "data = pickle.load(infile)\n",
        "\n",
        "lemma = pd.DataFrame(data, columns=[\"lemmatized_text\"])\n",
        "lemma.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "mSDYH4Koq2PO",
        "outputId": "e1100f7b-0bbc-4d3d-c84f-860083f5088b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     lemmatized_text\n",
              "0  wonder enlighten car see day door sport car lo...\n",
              "1  nntp post host carson washington edu fair numb...\n",
              "2  folks mac plus finally give ghost weekend star...\n",
              "3  nntp post host amber ssd csd harris com robert...\n",
              "4  article cowcb world std com tombaker world std..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f17c9e96-d488-4cb7-81d4-c1f211374cb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wonder enlighten car see day door sport car lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nntp post host carson washington edu fair numb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>folks mac plus finally give ghost weekend star...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nntp post host amber ssd csd harris com robert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>article cowcb world std com tombaker world std...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f17c9e96-d488-4cb7-81d4-c1f211374cb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f17c9e96-d488-4cb7-81d4-c1f211374cb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f17c9e96-d488-4cb7-81d4-c1f211374cb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_gen = [doc.split() for doc in lemma[\"lemmatized_text\"]]"
      ],
      "metadata": {
        "id": "9CyQIJB-K6Tu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Word2Vec"
      ],
      "metadata": {
        "id": "CEhX4k_gsSZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(corpus_gen, size=100, min_count=566) \n",
        "# Parameter \"size\" specifies the the dimensionality of the vector, meaning the vector size "
      ],
      "metadata": {
        "id": "XI1SbdtRse00"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('word2vec.model')"
      ],
      "metadata": {
        "id": "fBq0mp5mrWCn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vocab.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlZz_KigKqUD",
        "outputId": "42a73985-00b2-4fda-8ec5-d18d3c726580"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['wonder', 'car', 'see', 'day', 'look', 'early', 'call', 'small', 'body', 'know', 'model', 'year', 'history', 'info', 'mail', 'thank', 'nntp', 'post', 'host', 'washington', 'edu', 'number', 'experience', 'send', 'message', 'speed', 'rate', 'add', 'card', 'disk', 'request', 'network', 'base', 'answer', 'guy', 'mac', 'give', 'start', 'life', 'way', 'new', 'machine', 'bit', 'maybe', 'question', 'anybody', 'expect', 'hear', 'suppose', 'access', 'price', 'line', 'like', 'go', 'display', 'probably', 'get', 'feel', 'well', 'great', 'good', 'opinion', 'people', 'use', 'take', 'size', 'money', 'hit', 'real', 'play', 'figure', 'actually', 'advance', 'email', 'news', 'time', 'truth', 'com', 'uucp', 'write', 'article', 'chip', 'far', 'low', 'level', 'stuff', 'pretty', 'require', 'address', 'phone', 'information', 'thing', 'person', 'sense', 'world', 'clear', 'memory', 'error', 'yes', 'quote', 'software', 'check', 'right', 'value', 'set', 'code', 'tell', 'apr', 'john', 'power', 'weapon', 'make', 'cost', 'need', 'control', 'government', 'individual', 'result', 'death', 'non', 'state', 'come', 'believe', 'hard', 'support', 'agree', 'hand', 'hope', 'course', 'term', 'say', 'mean', 'follow', 'kill', 'read', 'present', 'argument', 'understand', 'point', 'allow', 'later', 'consider', 'speak', 'company', 'today', 'think', 'sure', 'instead', 'try', 'file', 'april', 'scsi', 'device', 'long', 'problem', 'love', 'statement', 'list', 'standard', 'version', 'show', 'note', 'exist', 'mode', 'fast', 'datum', 'correct', 'fact', 'ibm', 'available', 'ftp', 'report', 'apple', 'drive', 'true', 'reference', 'win', 'change', 'help', 'appreciate', 'design', 'board', 'hardware', 'work', 'technology', 'lose', 'wrong', 'mention', 'product', 'buy', 'run', 'sell', 'bike', 'want', 'org', 'david', 'hold', 'end', 'different', 'explain', 'god', 'jews', 'case', 'decide', 'lead', 'man', 'christian', 'mind', 'create', 'image', 'live', 'example', 'press', 'kind', 'little', 'jesus', 'second', 'bad', 'bible', 'guess', 'faith', 'child', 'assume', 'simply', 'pub', 'type', 'old', 'learn', 'religion', 'nasa', 'gov', 'mark', 'city', 'receive', 'space', 'likely', 'let', 'study', 'team', 'key', 'provide', 'force', 'source', 'place', 'return', 'mike', 'build', 'system', 'major', 'single', 'offer', 'black', 'player', 'graphic', 'high', 'sound', 'include', 'head', 'ask', 'contact', 'reply', 'form', 'group', 'happen', 'war', 'short', 'cause', 'die', 'certainly', 'program', 'save', 'general', 'big', 'format', 'word', 'sort', 'application', 'job', 'able', 'deal', 'reason', 'driver', 'pay', 'close', 'house', 'security', 'steve', 'university', 'remember', 'similar', 'situation', 'turn', 'couple', 'friend', 'claim', 'stop', 'month', 'light', 'law', 'center', 'away', 'ago', 'continue', 'cover', 'book', 'interested', 'important', 'date', 'view', 'possible', 'difference', 'output', 'simple', 'entry', 'mit', 'sun', 'window', 'matter', 'contain', 'order', 'season', 'package', 'data', 'free', 'copy', 'appear', 'fax', 'comment', 'service', 'monitor', 'box', 'leave', 'involve', 'user', 'care', 'subject', 'purpose', 'isn', 'current', 'attack', 'accept', 'earth', 'paul', 'lot', 'ground', 'wouldn', 'local', 'face', 'stand', 'michael', 'better', 'israel', 'easy', 'act', 'member', 'week', 'begin', 'bring', 'effect', 'encryption', 'drug', 'public', 'large', 'gun', 'rule', 'have', 'talk', 'action', 'carry', 'function', 'open', 'issue', 'white', 'game', 'home', 'certain', 'american', 'net', 'max', 'idea', 'original', 'armenian', 'turkish', 'woman', 'armenians', 'church', 'position', 'pass', 'protect', 'country', 'windows', 'area', 'release', 'plan', 'human', 'science', 'national', 'research', 'test', 'event', 'server', 'break', 'apply', 'evidence', 'sale', 'crime', 'president', 'discussion', 'screen', 'period', 'video', 'school', 'color', 'suggest', 'internet', 'netcom', 'hockey', 'israeli'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['car']\n",
        "\n",
        "# Showing the vector for the word 'car'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmFqmsEpKwzy",
        "outputId": "529f4474-16ca-4b77-96e3-d213d85ea3c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.4911838 ,  0.27105722, -1.4270626 ,  0.6491862 , -0.13189852,\n",
              "       -0.29328054, -1.1664724 , -0.21991941, -1.0196466 , -0.36969563,\n",
              "        0.9672887 , -0.85468525,  1.35709   ,  1.1705366 ,  0.65667605,\n",
              "       -1.1745235 ,  1.33018   ,  0.06567831,  0.62622154,  0.21721831,\n",
              "        0.4494125 , -0.3853249 ,  0.37854084, -0.60643023,  0.14845395,\n",
              "        0.7716984 ,  0.74779856,  0.261994  ,  0.4342244 , -0.07775514,\n",
              "        0.35075837, -0.7906314 , -0.40388307,  0.53183556, -1.5614841 ,\n",
              "        0.2799971 , -0.01042147,  0.7340095 , -0.40339077, -0.7933223 ,\n",
              "       -0.08589507,  0.50297046, -0.44708347, -1.3901651 ,  0.7212974 ,\n",
              "        0.23232135, -0.05688187, -1.120604  ,  0.40177825,  0.07601008,\n",
              "       -1.3912517 ,  0.6709938 , -1.2783272 , -0.5913585 ,  0.1221378 ,\n",
              "       -0.08490321,  0.9235072 , -0.32661763,  0.22122341, -2.7657511 ,\n",
              "        1.7677401 , -0.02230113,  0.331445  , -2.2923014 , -0.08860268,\n",
              "        0.02658519,  0.11294232, -0.84872794,  0.30872205, -0.21229304,\n",
              "       -0.48900577, -0.45093536,  0.16722037, -1.2631501 ,  0.799483  ,\n",
              "        0.37151858, -2.023308  , -0.13321653, -1.4340208 ,  0.51257145,\n",
              "       -0.64446443,  0.6592036 , -0.93080217,  0.9368405 ,  0.97590256,\n",
              "        1.2693907 , -0.03874127, -0.63834137, -1.3554885 , -1.0640006 ,\n",
              "       -0.8523282 ,  0.657894  ,  2.3771174 , -0.4432352 , -1.0964377 ,\n",
              "       -0.25125632, -0.17554912, -1.3970376 , -1.3434583 , -0.0601557 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the words that are likely similar to car\n",
        "\n",
        "model.wv.most_similar('car')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJRteBFeLbHf",
        "outputId": "2aff6150-20c2-447d-f0d1-498eb3f935ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bike', 0.6998724937438965),\n",
              " ('buy', 0.6064159870147705),\n",
              " ('turn', 0.5239871740341187),\n",
              " ('get', 0.5017094612121582),\n",
              " ('friend', 0.48795849084854126),\n",
              " ('pay', 0.48485440015792847),\n",
              " ('price', 0.48425495624542236),\n",
              " ('figure', 0.4812729060649872),\n",
              " ('speed', 0.47923627495765686),\n",
              " ('light', 0.47116899490356445)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['bike', 'machine'], topn=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g18cVtzLjyp",
        "outputId": "492c2e84-908e-4fe8-f38f-f5d7dcadd198"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fast', 0.686661958694458)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.most_similar(positive=['edu', 'woman'], topn=1))\n",
        "print(model.wv.most_similar(positive=['great', 'money'], topn=1))\n",
        "print(model.wv.most_similar(positive=['opinion', 'write'], topn=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCXg8d2mLsWX",
        "outputId": "1253da8d-e22d-4beb-e44f-b345c0a71590"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('john', 0.565531849861145)]\n",
            "[('deal', 0.8038709163665771)]\n",
            "[('uucp', 0.7215341329574585)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a corpus as a list, where for each document the list entry consists of the list of word2vec embeddings of the words in this document. Remove from it the empty documents. Why were those generated? Aggregate the values at a document level (i.e., one embedding per document) by averaging the word embeddings. "
      ],
      "metadata": {
        "id": "_m8hmVdMPfq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus2 = []\n",
        "\n",
        "for doc in corpus_gen:\n",
        "  docs = []\n",
        "  for word in doc:\n",
        "    if list(model.wv.vocab.keys()).count(word) > 0:\n",
        "      docs.append(model.wv[word])\n",
        "    if len(docs) != 0:\n",
        "      corpus2.append(np.mean(docs, axis=0))"
      ],
      "metadata": {
        "id": "0KQ0WKcbPnN9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word2VecModel = pd.DataFrame(corpus2)\n",
        "Word2VecModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "1sBf3jGAPhNR",
        "outputId": "f64cc6fb-522d-4729-f0b8-5656a9393eaa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0         1         2         3         4         5         6   \\\n",
              "0        0.251094  0.229564 -0.151505  0.111964  0.168110 -0.253534  0.046320   \n",
              "1        0.251094  0.229564 -0.151505  0.111964  0.168110 -0.253534  0.046320   \n",
              "2        0.871139  0.250311 -0.789284  0.380575  0.018106 -0.273407 -0.560076   \n",
              "3        0.682268  0.213369 -0.698855  0.015675  0.089140 -0.245368 -0.577999   \n",
              "4        0.315724  0.070513 -0.535066  0.149907  0.093312 -0.332891 -0.473222   \n",
              "...           ...       ...       ...       ...       ...       ...       ...   \n",
              "1431733 -0.218732  0.154076 -0.393247  0.138099  0.507014 -0.359997 -0.426432   \n",
              "1431734 -0.218732  0.154076 -0.393247  0.138099  0.507014 -0.359997 -0.426432   \n",
              "1431735 -0.273379  0.144365 -0.322036  0.128128  0.425575 -0.312848 -0.324828   \n",
              "1431736 -0.273379  0.144365 -0.322036  0.128128  0.425575 -0.312848 -0.324828   \n",
              "1431737 -0.273379  0.144365 -0.322036  0.128128  0.425575 -0.312848 -0.324828   \n",
              "\n",
              "               7         8         9   ...        90        91        92  \\\n",
              "0       -0.269943 -0.779019  0.042001  ...  0.271170  0.071123  0.083710   \n",
              "1       -0.269943 -0.779019  0.042001  ...  0.271170  0.071123  0.083710   \n",
              "2       -0.244931 -0.899333 -0.163847  ... -0.290579  0.364508  1.230414   \n",
              "3       -0.320122 -1.100727  0.026189  ... -0.034674  0.474498  0.778732   \n",
              "4       -0.389201 -1.073397  0.102204  ... -0.207852  0.286048  0.799602   \n",
              "...           ...       ...       ...  ...       ...       ...       ...   \n",
              "1431733  0.197307 -0.182476 -0.372101  ...  0.271989 -0.209927  0.072577   \n",
              "1431734  0.197307 -0.182476 -0.372101  ...  0.271989 -0.209927  0.072577   \n",
              "1431735  0.141425 -0.194524 -0.305694  ...  0.276879 -0.151526  0.124989   \n",
              "1431736  0.141425 -0.194524 -0.305694  ...  0.276879 -0.151526  0.124989   \n",
              "1431737  0.141425 -0.194524 -0.305694  ...  0.276879 -0.151526  0.124989   \n",
              "\n",
              "               93        94        95        96        97        98        99  \n",
              "0        0.058753  0.379020  0.282407  0.498034  0.473872 -0.176473 -0.155580  \n",
              "1        0.058753  0.379020  0.282407  0.498034  0.473872 -0.176473 -0.155580  \n",
              "2       -0.192241 -0.358709  0.015575  0.161242 -0.461583 -0.759966 -0.107868  \n",
              "3       -0.306429 -0.075673 -0.042238  0.288156 -0.255211 -0.785995  0.210238  \n",
              "4       -0.606088 -0.052077 -0.065621 -0.035220 -0.367099 -0.655491  0.139644  \n",
              "...           ...       ...       ...       ...       ...       ...       ...  \n",
              "1431733 -0.437503  0.156518  0.274763  0.423609  0.014913 -0.320573  0.463255  \n",
              "1431734 -0.437503  0.156518  0.274763  0.423609  0.014913 -0.320573  0.463255  \n",
              "1431735 -0.308961  0.144907  0.335160  0.315662  0.059374 -0.220904  0.371786  \n",
              "1431736 -0.308961  0.144907  0.335160  0.315662  0.059374 -0.220904  0.371786  \n",
              "1431737 -0.308961  0.144907  0.335160  0.315662  0.059374 -0.220904  0.371786  \n",
              "\n",
              "[1431738 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b58c7b59-2844-4401-9b69-fd17ddc1d942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.251094</td>\n",
              "      <td>0.229564</td>\n",
              "      <td>-0.151505</td>\n",
              "      <td>0.111964</td>\n",
              "      <td>0.168110</td>\n",
              "      <td>-0.253534</td>\n",
              "      <td>0.046320</td>\n",
              "      <td>-0.269943</td>\n",
              "      <td>-0.779019</td>\n",
              "      <td>0.042001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271170</td>\n",
              "      <td>0.071123</td>\n",
              "      <td>0.083710</td>\n",
              "      <td>0.058753</td>\n",
              "      <td>0.379020</td>\n",
              "      <td>0.282407</td>\n",
              "      <td>0.498034</td>\n",
              "      <td>0.473872</td>\n",
              "      <td>-0.176473</td>\n",
              "      <td>-0.155580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.251094</td>\n",
              "      <td>0.229564</td>\n",
              "      <td>-0.151505</td>\n",
              "      <td>0.111964</td>\n",
              "      <td>0.168110</td>\n",
              "      <td>-0.253534</td>\n",
              "      <td>0.046320</td>\n",
              "      <td>-0.269943</td>\n",
              "      <td>-0.779019</td>\n",
              "      <td>0.042001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271170</td>\n",
              "      <td>0.071123</td>\n",
              "      <td>0.083710</td>\n",
              "      <td>0.058753</td>\n",
              "      <td>0.379020</td>\n",
              "      <td>0.282407</td>\n",
              "      <td>0.498034</td>\n",
              "      <td>0.473872</td>\n",
              "      <td>-0.176473</td>\n",
              "      <td>-0.155580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.871139</td>\n",
              "      <td>0.250311</td>\n",
              "      <td>-0.789284</td>\n",
              "      <td>0.380575</td>\n",
              "      <td>0.018106</td>\n",
              "      <td>-0.273407</td>\n",
              "      <td>-0.560076</td>\n",
              "      <td>-0.244931</td>\n",
              "      <td>-0.899333</td>\n",
              "      <td>-0.163847</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.290579</td>\n",
              "      <td>0.364508</td>\n",
              "      <td>1.230414</td>\n",
              "      <td>-0.192241</td>\n",
              "      <td>-0.358709</td>\n",
              "      <td>0.015575</td>\n",
              "      <td>0.161242</td>\n",
              "      <td>-0.461583</td>\n",
              "      <td>-0.759966</td>\n",
              "      <td>-0.107868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.682268</td>\n",
              "      <td>0.213369</td>\n",
              "      <td>-0.698855</td>\n",
              "      <td>0.015675</td>\n",
              "      <td>0.089140</td>\n",
              "      <td>-0.245368</td>\n",
              "      <td>-0.577999</td>\n",
              "      <td>-0.320122</td>\n",
              "      <td>-1.100727</td>\n",
              "      <td>0.026189</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034674</td>\n",
              "      <td>0.474498</td>\n",
              "      <td>0.778732</td>\n",
              "      <td>-0.306429</td>\n",
              "      <td>-0.075673</td>\n",
              "      <td>-0.042238</td>\n",
              "      <td>0.288156</td>\n",
              "      <td>-0.255211</td>\n",
              "      <td>-0.785995</td>\n",
              "      <td>0.210238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.315724</td>\n",
              "      <td>0.070513</td>\n",
              "      <td>-0.535066</td>\n",
              "      <td>0.149907</td>\n",
              "      <td>0.093312</td>\n",
              "      <td>-0.332891</td>\n",
              "      <td>-0.473222</td>\n",
              "      <td>-0.389201</td>\n",
              "      <td>-1.073397</td>\n",
              "      <td>0.102204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.207852</td>\n",
              "      <td>0.286048</td>\n",
              "      <td>0.799602</td>\n",
              "      <td>-0.606088</td>\n",
              "      <td>-0.052077</td>\n",
              "      <td>-0.065621</td>\n",
              "      <td>-0.035220</td>\n",
              "      <td>-0.367099</td>\n",
              "      <td>-0.655491</td>\n",
              "      <td>0.139644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431733</th>\n",
              "      <td>-0.218732</td>\n",
              "      <td>0.154076</td>\n",
              "      <td>-0.393247</td>\n",
              "      <td>0.138099</td>\n",
              "      <td>0.507014</td>\n",
              "      <td>-0.359997</td>\n",
              "      <td>-0.426432</td>\n",
              "      <td>0.197307</td>\n",
              "      <td>-0.182476</td>\n",
              "      <td>-0.372101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271989</td>\n",
              "      <td>-0.209927</td>\n",
              "      <td>0.072577</td>\n",
              "      <td>-0.437503</td>\n",
              "      <td>0.156518</td>\n",
              "      <td>0.274763</td>\n",
              "      <td>0.423609</td>\n",
              "      <td>0.014913</td>\n",
              "      <td>-0.320573</td>\n",
              "      <td>0.463255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431734</th>\n",
              "      <td>-0.218732</td>\n",
              "      <td>0.154076</td>\n",
              "      <td>-0.393247</td>\n",
              "      <td>0.138099</td>\n",
              "      <td>0.507014</td>\n",
              "      <td>-0.359997</td>\n",
              "      <td>-0.426432</td>\n",
              "      <td>0.197307</td>\n",
              "      <td>-0.182476</td>\n",
              "      <td>-0.372101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271989</td>\n",
              "      <td>-0.209927</td>\n",
              "      <td>0.072577</td>\n",
              "      <td>-0.437503</td>\n",
              "      <td>0.156518</td>\n",
              "      <td>0.274763</td>\n",
              "      <td>0.423609</td>\n",
              "      <td>0.014913</td>\n",
              "      <td>-0.320573</td>\n",
              "      <td>0.463255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431735</th>\n",
              "      <td>-0.273379</td>\n",
              "      <td>0.144365</td>\n",
              "      <td>-0.322036</td>\n",
              "      <td>0.128128</td>\n",
              "      <td>0.425575</td>\n",
              "      <td>-0.312848</td>\n",
              "      <td>-0.324828</td>\n",
              "      <td>0.141425</td>\n",
              "      <td>-0.194524</td>\n",
              "      <td>-0.305694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.276879</td>\n",
              "      <td>-0.151526</td>\n",
              "      <td>0.124989</td>\n",
              "      <td>-0.308961</td>\n",
              "      <td>0.144907</td>\n",
              "      <td>0.335160</td>\n",
              "      <td>0.315662</td>\n",
              "      <td>0.059374</td>\n",
              "      <td>-0.220904</td>\n",
              "      <td>0.371786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431736</th>\n",
              "      <td>-0.273379</td>\n",
              "      <td>0.144365</td>\n",
              "      <td>-0.322036</td>\n",
              "      <td>0.128128</td>\n",
              "      <td>0.425575</td>\n",
              "      <td>-0.312848</td>\n",
              "      <td>-0.324828</td>\n",
              "      <td>0.141425</td>\n",
              "      <td>-0.194524</td>\n",
              "      <td>-0.305694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.276879</td>\n",
              "      <td>-0.151526</td>\n",
              "      <td>0.124989</td>\n",
              "      <td>-0.308961</td>\n",
              "      <td>0.144907</td>\n",
              "      <td>0.335160</td>\n",
              "      <td>0.315662</td>\n",
              "      <td>0.059374</td>\n",
              "      <td>-0.220904</td>\n",
              "      <td>0.371786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431737</th>\n",
              "      <td>-0.273379</td>\n",
              "      <td>0.144365</td>\n",
              "      <td>-0.322036</td>\n",
              "      <td>0.128128</td>\n",
              "      <td>0.425575</td>\n",
              "      <td>-0.312848</td>\n",
              "      <td>-0.324828</td>\n",
              "      <td>0.141425</td>\n",
              "      <td>-0.194524</td>\n",
              "      <td>-0.305694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.276879</td>\n",
              "      <td>-0.151526</td>\n",
              "      <td>0.124989</td>\n",
              "      <td>-0.308961</td>\n",
              "      <td>0.144907</td>\n",
              "      <td>0.335160</td>\n",
              "      <td>0.315662</td>\n",
              "      <td>0.059374</td>\n",
              "      <td>-0.220904</td>\n",
              "      <td>0.371786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1431738 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b58c7b59-2844-4401-9b69-fd17ddc1d942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b58c7b59-2844-4401-9b69-fd17ddc1d942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b58c7b59-2844-4401-9b69-fd17ddc1d942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TWSM/w2v_model.pkl', 'wb') as f:\n",
        "    pickle.dump(Word2VecModel, f)"
      ],
      "metadata": {
        "id": "-whwGTtM_ZYn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the most similar words to the embedding representing the first document from 10.\n",
        "Use cosine() to determine the document on the corpus most similar to it"
      ],
      "metadata": {
        "id": "vqRKINIgAEvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.argmax(model.wv.cosine_similarities(Word2VecModel.iloc[0,:], model.wv.vectors))\n",
        "print(index)\n",
        "model.wv.index2word[index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7FkOchC-AA0g",
        "outputId": "9bddd831-3f4f-43e5-dffd-35c91ce6d63a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wonder'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Doc2Vec"
      ],
      "metadata": {
        "id": "pm_qhUHqDj1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run gensim doc2vec model on corpus_gen (vector_size=100, min_count=566). (Note: Doc2vec requires tagged documents). Determine the embedding representation for the first document as well as the document in the dataset most similar to it. Compare it to the result in 10. Generate the final corpus as a data frame and store it in GoogleDrive as DoctoVecModel.pkl."
      ],
      "metadata": {
        "id": "yJx8ZfomEX4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the tagged document\n",
        "\n",
        "corpus_tagged = []\n",
        "\n",
        "for i, tokens in enumerate(corpus_gen):\n",
        "  corpus_tagged.append(TaggedDocument(tokens, [i]))"
      ],
      "metadata": {
        "id": "tmVdfry2Ecdu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tagged[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndyUs_dIDmaH",
        "outputId": "d62f5c49-bd65-4c05-f252-cc6c0385f932"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['wonder', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'small', 'addition', 'bumper', 'separate', 'rest', 'body', 'know', 'tellme', 'model', 'engine', 'specs', 'year', 'production', 'car', 'history', 'info', 'funky', 'looking', 'car', 'mail', 'thank'], tags=[0]),\n",
              " TaggedDocument(words=['nntp', 'post', 'host', 'carson', 'washington', 'edu', 'fair', 'number', 'brave', 'soul', 'upgrade', 'clock', 'oscillator', 'share', 'experience', 'poll', 'send', 'brief', 'message', 'detailing', 'experience', 'procedure', 'speed', 'attain', 'cpu', 'rate', 'speed', 'add', 'card', 'adapters', 'heat', 'sink', 'hour', 'usage', 'day', 'floppy', 'disk', 'functionality', 'floppy', 'especially', 'request', 'summarize', 'day', 'add', 'network', 'knowledge', 'base', 'clock', 'upgrade', 'haven', 'answer', 'poll', 'thank', 'guy', 'kuo', 'guykuo', 'washington', 'edu'], tags=[1]),\n",
              " TaggedDocument(words=['folks', 'mac', 'plus', 'finally', 'give', 'ghost', 'weekend', 'start', 'life', 'way', 'sooo', 'market', 'new', 'machine', 'bit', 'sooner', 'intend', 'look', 'pick', 'powerbook', 'maybe', 'bunch', 'question', 'hopefully', 'somebody', 'answer', 'anybody', 'know', 'dirt', 'round', 'powerbook', 'introduction', 'expect', 'hear', 'suppose', 'appearence', 'summer', 'haven', 'hear', 'anymore', 'access', 'macleak', 'wonder', 'anybody', 'info', 'anybody', 'hear', 'rumor', 'price', 'drop', 'powerbook', 'line', 'like', 'one', 'duo', 'go', 'recently', 'impression', 'display', 'probably', 'swing', 'get', 'disk', 'feel', 'well', 'display', 'yea', 'look', 'great', 'store', 'wow', 'good', 'solicit', 'opinion', 'people', 'use', 'day', 'day', 'worth', 'take', 'disk', 'size', 'money', 'hit', 'active', 'display', 'realize', 'real', 'subjective', 'question', 'play', 'machine', 'store', 'breifly', 'figure', 'opinion', 'somebody', 'actually', 'use', 'machine', 'daily', 'prove', 'helpful', 'hellcat', 'perform', 'thank', 'bunch', 'advance', 'info', 'email', 'post', 'summary', 'news', 'reading', 'time', 'premium', 'final', 'corner', 'tom', 'willis', 'twillis', 'ecn', 'purdue', 'edu', 'purdue', 'electrical', 'engineering', 'conviction', 'dangerous', 'enemy', 'truth', 'lie', 'nietzsche'], tags=[2])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_tagged = Doc2Vec(corpus_tagged, vector_size=100, min_count=566)"
      ],
      "metadata": {
        "id": "T9RImClSEuq1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding representations (infer vector) of the first document \n",
        "\n",
        "inf_vector = model_tagged.infer_vector(corpus_tagged[0][0])\n",
        "\n",
        "inf_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdGso5EPE92W",
        "outputId": "3a40e878-1744-4ff1-d33e-6440b99227da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00343389,  0.05433059, -0.0343034 ,  0.02397159, -0.01670114,\n",
              "       -0.03579214, -0.02394407, -0.10346383, -0.02407631, -0.06662145,\n",
              "       -0.02115452, -0.01927171,  0.0817785 ,  0.03106043,  0.0981102 ,\n",
              "       -0.06753811,  0.00577327,  0.05796448,  0.01148386, -0.02031339,\n",
              "        0.05609358,  0.03103106,  0.02853415,  0.0450988 , -0.04588893,\n",
              "        0.06154156, -0.01102371, -0.01484922,  0.04037267, -0.06565206,\n",
              "        0.01656311,  0.04547077,  0.01263468,  0.01129479, -0.00248212,\n",
              "       -0.06658413, -0.03082949, -0.00124186,  0.01133191, -0.00326324,\n",
              "       -0.03676914,  0.04329317, -0.00562959, -0.0463122 , -0.04550274,\n",
              "       -0.00917411, -0.00603131,  0.01553557, -0.05613521,  0.01835759,\n",
              "        0.03069397,  0.09705859, -0.02355724,  0.00476354,  0.05521968,\n",
              "       -0.04971575,  0.02490221, -0.04348683, -0.05098116, -0.09985958,\n",
              "        0.05203902, -0.06488647,  0.0051053 , -0.05141764,  0.03525161,\n",
              "        0.06276892, -0.00601061, -0.03281502, -0.01759314, -0.05934285,\n",
              "        0.01723481, -0.00869369,  0.00874016, -0.01182349,  0.01068411,\n",
              "        0.07676511, -0.05691974,  0.08060759, -0.05577339,  0.05013778,\n",
              "       -0.00889049, -0.01914819, -0.04818592,  0.01686006, -0.02783443,\n",
              "        0.11366439, -0.04398645, -0.00600342,  0.00742862, -0.04846824,\n",
              "       -0.03781111,  0.04435109,  0.00824763, -0.05243381, -0.00773119,\n",
              "       -0.00329666,  0.0268167 ,  0.02685136, -0.07407447,  0.02612945],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Doc2VecModel = [model_tagged.infer_vector(doc) for doc, doc_id in corpus_tagged]"
      ],
      "metadata": {
        "id": "Z_t2as2jsoXK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TWSM/d2v_model.pkl', 'wb') as f:\n",
        "    pickle.dump(Doc2VecModel, f)"
      ],
      "metadata": {
        "id": "tuLDI4kZszuZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dnuBetNBtIYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}